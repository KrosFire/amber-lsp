---
source: tests/grammar/alpha034.rs
expression: "compiler.tokenize(r#\"\n        let x = \"my \\\"interpolated\\\" string {name} end\";\n\n        $this --should be - tokenized \\$$\n        \"unclosed string\n\n        abcd {let x = 10\n    \"#)"
---
[
    (
        Token(
            "let",
        ),
        9..12,
    ),
    (
        Token(
            "x",
        ),
        13..14,
    ),
    (
        Token(
            "=",
        ),
        15..16,
    ),
    (
        Token(
            "\"",
        ),
        17..18,
    ),
    (
        Token(
            "my",
        ),
        18..20,
    ),
    (
        Token(
            "\\",
        ),
        21..22,
    ),
    (
        Token(
            "\"",
        ),
        22..23,
    ),
    (
        Token(
            "interpolated",
        ),
        23..35,
    ),
    (
        Token(
            "\\",
        ),
        35..36,
    ),
    (
        Token(
            "\"",
        ),
        36..37,
    ),
    (
        Token(
            "string",
        ),
        38..44,
    ),
    (
        Token(
            "{",
        ),
        45..46,
    ),
    (
        Token(
            "name",
        ),
        46..50,
    ),
    (
        Token(
            "}",
        ),
        50..51,
    ),
    (
        Token(
            "end",
        ),
        52..55,
    ),
    (
        Token(
            "\"",
        ),
        55..56,
    ),
    (
        Token(
            ";",
        ),
        56..57,
    ),
    (
        Token(
            "$",
        ),
        67..68,
    ),
    (
        Token(
            "this",
        ),
        68..72,
    ),
    (
        Token(
            "-",
        ),
        73..74,
    ),
    (
        Token(
            "-",
        ),
        74..75,
    ),
    (
        Token(
            "should",
        ),
        75..81,
    ),
    (
        Token(
            "be",
        ),
        82..84,
    ),
    (
        Token(
            "-",
        ),
        85..86,
    ),
    (
        Token(
            "tokenized",
        ),
        87..96,
    ),
    (
        Token(
            "\\",
        ),
        97..98,
    ),
    (
        Token(
            "$",
        ),
        98..99,
    ),
    (
        Token(
            "$",
        ),
        99..100,
    ),
    (
        Token(
            "\"",
        ),
        109..110,
    ),
    (
        Token(
            "unclosed",
        ),
        110..118,
    ),
    (
        Token(
            "string",
        ),
        119..125,
    ),
    (
        Token(
            "abcd",
        ),
        135..139,
    ),
    (
        Token(
            "{",
        ),
        140..141,
    ),
    (
        Token(
            "let",
        ),
        141..144,
    ),
    (
        Token(
            "x",
        ),
        145..146,
    ),
    (
        Token(
            "=",
        ),
        147..148,
    ),
    (
        Token(
            "10",
        ),
        149..151,
    ),
]
